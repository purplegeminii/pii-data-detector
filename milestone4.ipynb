{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PII Detection\n",
    "## Authors\n",
    "Victor Quagraine, Hutton Amison-Addy, Delali Nsiah Asare\n",
    "\n",
    "## Problem\n",
    "PII or Personal Identifiable Information are information details that can be used to identify individuals. Our task was to create a model capable of identifying these PII in any given document.\n",
    "\n",
    "## Approach\n",
    "We considered NLP to tackle this problem since our dataset involved text used in context with each other. Our selected model was the Bidirectional Long Short Term Model selected to gain context of how words are used in a document and their relation with other words before and after them\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vk6euHHuV8Kv"
   },
   "source": [
    "# Dependency Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OvAIO5LM-Oco",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r6cPZTu0WJyX"
   },
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJW1jt5f-hdw",
    "outputId": "43a6d30e-6b1e-413d-dd5f-621f96593873",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/piidata'):\n",
    "#     print(os.join)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vc4CU4J3WbyI"
   },
   "source": [
    "# Data Preprocessing\n",
    "Our dataset was presented in a json format containing various document id's, documents and token labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2LQmyW3p-Z6A",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# train_df =  pd.read_json(\"/content/drive/MyDrive/Colab Notebooks/Datasets/pii/train.json\")#laoding the data\n",
    "train_df =  pd.read_json(\"/kaggle/input/piidata/train.json\")#laoding the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is split into a training/validation set and a held out set for testing after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e4dSgxwtmEUR",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df, testing_df = train_test_split(train_df, test_size=0.2, random_state=42)#training set, held out set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 857
    },
    "id": "cRQ96hbcLPaj",
    "outputId": "e082469b-9ad0-4fe4-b7e0-769e22bf6073",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df.head()# first five items in the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k75DGVOxWm8N"
   },
   "source": [
    "Our load unpack function unpacks the tokens from the documents to form the larger dataset of tokens and labels and returns the row id, document number, the token id, the token and its label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k5_MB_m4Be49",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def list_unpack(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    row_ids=[]\n",
    "    token=[]\n",
    "    labels=[]\n",
    "    document=[]\n",
    "    token_id=[]\n",
    "    row_id = 0\n",
    "\n",
    "    for i in range(0,len(df['tokens'])):\n",
    "        document += [df['document'].iloc[i]]*len(df['tokens'].iloc[i])\n",
    "        for j in range(0,len(df['tokens'].iloc[i])):\n",
    "            token_id.append(j)\n",
    "            row_ids.append(row_id)\n",
    "            row_id+=1\n",
    "        token += df['tokens'].iloc[i]\n",
    "        labels += df['labels'].iloc[i]\n",
    "\n",
    "    temp_dict = {\n",
    "        \"row_id\": row_ids,\n",
    "        \"document\": document,\n",
    "        \"token_id\": token_id,\n",
    "        \"token\": token,\n",
    "        \"label\": labels\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame(temp_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4a17RWOkW4dl"
   },
   "source": [
    "Unpacking the training dataset tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FAlozKjVBl4Y",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_data=list_unpack(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "PxjLTc0aW8OY",
    "outputId": "66e29e9a-6a43-4304-c334-1b19d17ea305",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GLjyHoVmXVlZ"
   },
   "source": [
    "# Spliting the dataset Into Features and labels\n",
    "X holds our token input for the model whilst y holds labels, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CuFkvoh1_bKV",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X = train_data['token']#tokens\n",
    "y = train_data['label']#labels\n",
    "labels= train_data['label'].unique()#unique labels for encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xmMmLaYrLwES",
    "outputId": "6856d272-6cf5-4662-d187-f9b6243298c6",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the encoder\n",
    "The labels are encoded to be used during the training of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HVF-97hL_88N",
    "outputId": "5ae915f6-cbba-4646-c265-12c566c2e28d",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "\n",
    "# Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "print(\"Label Encoded Labels:\", encoded_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ngn7coVSXoP1"
   },
   "source": [
    "# Create Train-Validation Split\n",
    "##### The training set after going through preprocesssing is being split in to the train set and the validation set which will be used to test for generalisation during each epoch.\n",
    "\n",
    "##### The set is split 80-20 for train to vaidate respectively.\n",
    "##### The set are also randomised to prevent overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AmMd7nAj__4r",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7jO3hppXvOR"
   },
   "source": [
    "# DataLoader\n",
    "To load the data into the model, we needed to create our own dataset object based on the Torch Dataset Object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uKBrN9tJCjrh",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the torch dataloader, we were able to prepare both training data and validation data in an object that could be used to train and validated the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Dataset\n",
    "train_dataset = CustomDataset(X_train.values, y_train.values)\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "#Validation Dataset\n",
    "validation_dataset = CustomDataset(X_val.values, y_val.values)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=2048, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yseEImutvC-y"
   },
   "source": [
    "# Definition of BiLSTM Model\n",
    "THe Bidirectional LSTM trains on data in both the normal and reverse direction the input comes in. This was to allow the model to gain a better context of words, how they are used and how they relate to each other depending on what comes after what.\n",
    "##### embed\n",
    "The torch module contains an embedding function which is able to perform word embedding on the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SfOf_w3GCpmw",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers, num_classes):\n",
    "        super(BiLSTM, self).__init__()#Inherits from the BiLSTM from the torch module\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)#the embedding function provided for the BiLSTM model from torch\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, bidirectional=True, batch_first=True)# definition of the LSTM from torch indicating the use of both forward and back traverse during raining\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)  # Bidirectional models implement two sets of hidden layers.\n",
    "\n",
    "    def forward(self, x):\n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        out = self.fc(lstm_out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NeP_bIhEYHlZ"
   },
   "source": [
    "# Vocabulary, Model, GPU device, Loss Function and Optimizer\n",
    "The vocab is a dictionary of unique tokens and their identifying index. The device is the processing units used for the batch training. THe Criterion/Loss uses a Cross Entropy loss and the optimizer uses the Adaptive Moment Estimation or Adam Optimizer.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kIJ_RHKeCwr_",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define vocabulary based on unique tokens in the dataset\n",
    "vocab = {token: idx for idx, token in enumerate(set(train_data['token']))}\n",
    "vocab_size = len(vocab)\n",
    "num_classes=len(labels)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')# if GPU cores are available use them for batch training else use the cpu \n",
    "model = BiLSTM(vocab_size, embed_size=100, hidden_size=100, num_layers=2, num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()#Loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)#Optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "execution": {
     "iopub.status.busy": "2024-04-05T22:39:22.147153Z",
     "iopub.status.idle": "2024-04-05T22:39:22.147513Z",
     "shell.execute_reply": "2024-04-05T22:39:22.147355Z",
     "shell.execute_reply.started": "2024-04-05T22:39:22.147336Z"
    },
    "id": "OZ8Md_y3C0OK",
    "outputId": "0088c1f7-8ae1-4279-f78c-774e7ca0f680",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "train_losses = []\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "accuracies = []\n",
    "num_epochs = 5\n",
    "fig, ax = plt.subplots()  # Creates figure and axis objects for plotting the loss, validation loss and accuracy\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        inputs, labels = batch\n",
    "        inputs = torch.tensor([vocab.get(token, 0) for token in inputs]).to(device)  # Converts tokens to indices\n",
    "\n",
    "     \n",
    "        labels = torch.tensor([label_encoder.transform([label])[0] for label in labels]).to(device)\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    # Appends the epoch loss to train_losses list\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    train_loss.append(epoch_loss)\n",
    "\n",
    "    # Performs validation\n",
    "    model.eval()  # Sets model to evaluation mode\n",
    "    val_running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_batch in validation_loader:\n",
    "            val_inputs, val_labels = val_batch\n",
    "            val_inputs = torch.tensor([vocab.get(token, 0) for token in val_inputs]).to(device)\n",
    "\n",
    "            # Encodes labels into numerical values\n",
    "            encoded_val_labels = [label_encoder.transform([label])[0] for label in val_labels]\n",
    "            val_labels = torch.tensor(encoded_val_labels).to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            val_outputs = model(val_inputs)\n",
    "            val_loss = criterion(val_outputs, val_labels)\n",
    "            val_running_loss += val_loss.item() * val_inputs.size(0)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(val_outputs, 1)\n",
    "            total_predictions += val_labels.size(0)\n",
    "            correct_predictions += (predicted == val_labels).sum().item()\n",
    "\n",
    "        # Calculate validation loss and accuracy\n",
    "        val_epoch_loss = val_running_loss / len(validation_loader.dataset)\n",
    "        valid_loss.append(val_epoch_loss)\n",
    "        accuracy = correct_predictions / total_predictions\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    # Plot training and validation losses along with accuracy after each epoch\n",
    "    ax.clear()\n",
    "    ax.plot(range(1, epoch + 2), train_loss, label='Training Loss')\n",
    "    ax.plot(range(1, epoch + 2), valid_loss, label='Validation Loss')\n",
    "    ax.plot(range(1, epoch + 2), accuracies, label='Accuracy')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss / Accuracy')\n",
    "    ax.set_title('Training and Validation Losses with Accuracy')\n",
    "    ax.legend()\n",
    "    display(fig)\n",
    "    clear_output(wait=True)\n",
    "\n",
    "plt.close()  # Close the plot after training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0pkmuBMrbktw"
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JUufgY0BF5xu",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# test_df =  pd.read_json(\"/content/drive/MyDrive/Colab Notebooks/Datasets/pii/test.json\")#laoding the data\n",
    "test_df=testing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UKhTE1eWbzwX",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test=list_unpack(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uH5XTc7zcWg1",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Xtest = test['token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dVH6ymSAhzDQ",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Converts words to indices using vocab and creates a tensor with the appropriate data type\n",
    "input_tensor = torch.tensor([vocab.get(word, 0) for word in Xtest.values], dtype=torch.long)\n",
    "\n",
    "# Ensures the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Performs forward pass without gradient computation\n",
    "with torch.no_grad():\n",
    "    predictions = model(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u32dBtJmdKwv",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "predicted_indices = torch.argmax(predictions, dim=1)\n",
    "\n",
    "predicted_labels = label_encoder.classes_[predicted_indices.cpu().numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OR1O9HEKlRqL",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test['predicted_labels']=predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HMQwEHsKlUto",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_split=test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-sZb5PDDzy4S"
   },
   "source": [
    "Confusion matrix for the Predictions. There are 3146 true positive values which is justifying the results of the evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V0BPeG4CDeTp",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "pd.DataFrame(confusion_matrix(test_split['label'], test_split['predicted_labels']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3t65Ty1oMU55"
   },
   "source": [
    "# Anaysis\n",
    "The evaluations metrics for the BiLSTM model. All the evaluation metrics used here lie between 0 and 1, inclusive.\n",
    "\n",
    "### Accuracy\n",
    "Accuracy takes the correct predictions over the total values in the observations. An accuracy score of \n",
    "# 0.99\n",
    "the model's prediction matches the actual value\n",
    "# 99%\n",
    "of the time.\n",
    "\n",
    "### Precision\n",
    "Precision checks how many times the model predicts a positive value correctly. It checks the number of positive predictions that were actually correct. A precision score of \n",
    "# 0.99\n",
    "indicates that the model is predicting positive values correctly about \n",
    "# 99% \n",
    "of the time.\n",
    "\n",
    "### Recall\n",
    "Recall answers the question 'How many actual positive values were identified by the model?'. Since the model has high recall, we know that about\n",
    "# 99% \n",
    "of the time, the model's predictions will closely match the value we expect.\n",
    "\n",
    "### F1\n",
    "F1 score is a weighted average of the model's precision and recall. A high recall of \n",
    "# 0.99\n",
    "shows that the model has both a high recall ability and high precision, which translates to a model that is likely generalisable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "URO5H9xgEcwY",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "accuracy = accuracy_score(test_split['label'], test_split['predicted_labels'])\n",
    "precision = precision_score(test_split['label'], test_split['predicted_labels'], average='micro')\n",
    "recall = recall_score(test_split['label'], test_split['predicted_labels'], average='micro')\n",
    "f1 = f1_score(test_split['label'], test_split['predicted_labels'], average='micro')\n",
    "\n",
    "print(f\"Accuracy score: {accuracy}\")\n",
    "print(f\"Precision score: {precision}\")\n",
    "print(f\"Recall score: {recall}\")\n",
    "print(f\"F1 score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lchzgd6_ZbCR"
   },
   "source": [
    "# Submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IKcK4AjOYEk9",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = test_split[['row_id','document', 'token_id', 'predicted_labels']]\n",
    "df.columns = ['row_id','document','token','label']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HMfwedmRerMP",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"/kaggle/input/piidata/submissions-mfc.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pYszXj75TlC7"
   },
   "source": [
    "# Evaluation file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j0omq_awTaKT",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = test_split[['row_id','document', 'token_id', 'label']]\n",
    "df.columns = ['row_id','document','token','label']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LaXRXQTXT0K7",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# df.to_csv(\"/content/drive/MyDrive/Colab Notebooks/Datasets/pii/sub/evaluations.csv\", index=False)\n",
    "df.to_json(\"/kaggle/input/piidata/results-mfc.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RBYLsDRybcYI"
   },
   "source": [
    "# Result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "htJjjic2Tt19",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "temp = {\n",
    "    'accuracy': accuracy,\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'f1_score': f1\n",
    "}\n",
    "df = pd.DataFrame(temp, index=[0,1,2,3])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bsRWUSr3dKPK",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# df.to_json(\"/content/drive/MyDrive/Colab Notebooks/Datasets/pii/sub/results-mfc.json\")\n",
    "df.to_json(\"/kaggle/input/piidata/results-mfc.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References \n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [
    {
     "datasetId": 4740163,
     "sourceId": 8040098,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30675,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
